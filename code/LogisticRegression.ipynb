{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "uploud the data"
      ],
      "metadata": {
        "id": "PQjUxkWdSzgW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yE7Zkis6B4v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from random import*\n",
        "from google.colab import drive\n",
        "from scipy.stats import multivariate_normal\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold,RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Read the CSV file into a DataFrame\n",
        "Xy_train = pd.read_csv(\"/content/drive/Shareddrives/ML/חלק ב/AirlineSatisfaction Dataset/Xy_train.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Processing"
      ],
      "metadata": {
        "id": "3N9UloSsV5DV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN3SJ_Burn4H"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_data =Xy_train\n",
        "\n",
        "# Remove unwanted class\n",
        "train_data[\"Class\"][train_data[\"Class\"] == \"IT IS SO BORING WORKING IN AN AIRPORT'S DESK OH MY GODDDDD\"] = None\n",
        "train_data[\"Class\"][train_data[\"Class\"] == 'Unknown'] = None\n",
        "\n",
        "\n",
        "for column in train_data[:-1].columns:train_data[column] = train_data[column].fillna(np.random.choice(train_data[column][~train_data[column].isna()]))\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_columns = train_data.select_dtypes(include=['object', 'category']).columns\n",
        "label_encoders = {}\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    train_data[column] = le.fit_transform(train_data[column])\n",
        "    print(train_data[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "print('______________________________________________________________________________________________________________________-')\n",
        "for column in train_data.columns: print(f\"column : {column} -> {list(train_data[column].unique())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fit Logistic Regression"
      ],
      "metadata": {
        "id": "Ll1WR1QVWBnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the data\n",
        "data = train_data\n",
        "\n",
        "# If the target variable is within the same file, separate it from features\n",
        "y = data['satisfaction']  # Replace 'target' with the actual target column name\n",
        "X = data.drop(columns=['satisfaction'])\n",
        "\n",
        "# Identifying categorical and numerical columns\n",
        "categorical_cols = ['Gender', 'Customer Type', 'Type of Travel', 'Class']\n",
        "numerical_cols = X.columns.difference(categorical_cols)\n",
        "\n",
        "# Define transformers for preprocessing\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Combine transformers using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Preprocess the data\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Define and train the logistic regression model\n",
        "model = LogisticRegression(max_iter=1000,penalty = None,solver='saga',)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = f1_score(y_test, y_pred)\n",
        "print(f'Test accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "t4H90ixEsPkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KFold\n",
        "\n"
      ],
      "metadata": {
        "id": "zGNhQRlzWi6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "import numpy as np\n",
        "\n",
        "# הגדרת רשת הפרמטרים (param_grid) עבור Logistic Regression\n",
        "param_grid = {\n",
        "  # 'C': np.logspace(-4, 4, 20),\n",
        "  'penalty': ['none'],\n",
        "  'solver': ['saga'],\n",
        "  'max_iter': [1000]\n",
        "}\n",
        "\n",
        "scoring = 'f1'\n",
        "grid_search = {}\n",
        "\n",
        "for cv in [10]:\n",
        "  kfold = KFold(n_splits=cv, shuffle=True, random_state=123)\n",
        "  grid_search[cv] = GridSearchCV(estimator=LogisticRegression(random_state=42),\n",
        "                                 param_grid=param_grid,\n",
        "                                 refit=True,\n",
        "                                 cv=kfold,\n",
        "                                 verbose=1,\n",
        "                                 scoring=scoring)\n",
        "\n",
        "  grid_search[cv].fit(X_train, y_train)\n",
        "\n",
        "# תוצאות רשת החיפוש\n",
        "for cv in grid_search:\n",
        "    print(f\"CV: {cv}\")\n",
        "    print(\"Best parameters found: \", grid_search[cv].best_params_)\n",
        "    print(\"Best F1 score: \", grid_search[cv].best_score_)\n"
      ],
      "metadata": {
        "id": "HKW--rePXd1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "k fold plot"
      ],
      "metadata": {
        "id": "dZH-cg2TWnjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results=[]\n",
        "for key , value in grid_search.items():\n",
        "  best_model = value.best_estimator_\n",
        "  print('k :' , key ,value.best_params_, '\\n')\n",
        "  print('k :' , key ,scoring, \"_score : \",value.best_score_ ,best_model.get_params(), '\\n')\n",
        "  # pd.DataFrame(value.cv_results_)\n",
        "  results.append({'cv': key,'test_acc': value.best_score_})\n",
        "\n",
        "# Convert results to DataFrame\n",
        "res = pd.DataFrame(results)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(13, 4))\n",
        "plt.plot(res['cv'], res['test_acc'], marker='o', markersize=4)\n",
        "plt.legend(['Train accuracy', f'test_{scoring}'])\n",
        "plt.xlabel('cv')\n",
        "plt.ylabel(f'Accuracy_{scoring}')\n",
        "plt.title(f'cv vs Max Depth Accuracy_{scoring}')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ifjm6locYLta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F7ojm_L8eXeX"
      }
    }
  ]
}