{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qt7FEDODqBW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "from random import*\n",
        "from google.colab import drive\n",
        "\n",
        "from scipy.stats import multivariate_normal\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score\n",
        "\n",
        "# Step 2: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 4: Read the CSV file into a DataFrame\n",
        "train_data = pd.read_csv(\"/content/drive/Shareddrives/ML/חלק ב/AirlineSatisfaction Dataset/Xy_train.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jtEa0IFMgVi"
      },
      "source": [
        "#Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from tree"
      ],
      "metadata": {
        "id": "SUosXkvNAqr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Remove unwanted class\n",
        "train_data[\"Class\"][train_data[\"Class\"] == \"IT IS SO BORING WORKING IN AN AIRPORT'S DESK OH MY GODDDDD\"] = None\n",
        "train_data[\"Class\"][train_data[\"Class\"] == 'Unknown'] = None\n",
        "\n",
        "#Retriving new values insted of Nones from the coulumn's distribution.\n",
        "for column in train_data[:-1].columns:train_data[column] = train_data[column].fillna(np.random.choice(train_data[column][~train_data[column].isna()]))\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_columns = train_data.select_dtypes(include=['object', 'category']).columns\n",
        "label_encoders = {}\n",
        "cat = []\n",
        "for column in train_data.columns:\n",
        "  if len(train_data[column].unique()) <=30 and column != 'satisfaction':\n",
        "    cat.append(column)\n",
        "train_data = pd.get_dummies(train_data, columns=cat)\n",
        "\n",
        "\n",
        "train_data['satisfaction'] = train_data['satisfaction'].apply(lambda x: x == 'satisfied')"
      ],
      "metadata": {
        "id": "zyBfAnk4BCFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_data['satisfaction']\n",
        "X_train = train_data.drop(columns = ['satisfaction'])"
      ],
      "metadata": {
        "id": "0vC7A2pYDjjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "e8fr_EXfei-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "id": "oEk5yhbXeVHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataPrep"
      ],
      "metadata": {
        "id": "JxlluxtIG9QG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DONT RUN!**"
      ],
      "metadata": {
        "id": "mdEhIzlRG0mP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Prep - Dealing with Nulls\n",
        "# filling Nulls as described in\n",
        "\n",
        "\n",
        "train_data['Leg room service'] = train_data['Leg room service'].fillna(train_data['Leg room service'].mode()[0])\n",
        "\n",
        "train_data['Arrival Delay in Minutes'] = train_data['Arrival Delay in Minutes'].fillna(train_data['Departure Delay in Minutes'] * 0.96)"
      ],
      "metadata": {
        "id": "xtRN482_Xzve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows where any of the specified columns have null values\n",
        "train_data = train_data.dropna(subset=['Gender', 'Customer Type', 'Age', 'Type of Travel', 'Class',\n",
        "       'Flight Distance', 'Plane colors', 'Inflight wifi service',\n",
        "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
        "       'Gate location', 'Food and drink', 'Seat comfort', 'On-board service',\n",
        "       'Baggage handling', 'Checkin service',\n",
        "       'Inflight service', 'Cleanliness', 'Departure Delay in Minutes',\n",
        "       'satisfaction'])"
      ],
      "metadata": {
        "id": "DB2QyQdfYeJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing Outliers From Age Column\n",
        "train_data['Age'] = train_data['Age'][train_data['Age']< 120]"
      ],
      "metadata": {
        "id": "_ozftoq7Yj-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34XcDgeuvT5J"
      },
      "outputs": [],
      "source": [
        "#Part3 - טיפול עם המשתנה class כמו שהוזכר בדוח\n",
        "\n",
        "# Get the indices of the 'Unknown' category\n",
        "indices_Unknown = train_data[train_data['Class'] == 'Unknown'].index\n",
        "\n",
        "# Calculate the size of each third\n",
        "n = len(indices_Unknown)\n",
        "one_third_size = n // 3\n",
        "\n",
        "# Ensure proper handling if the number of 'Unknown' is not perfectly divisible by 3\n",
        "additional = n % 3\n",
        "\n",
        "# Split and assign the new categories\n",
        "train_data.loc[indices_Unknown[:one_third_size], 'Class'] = 'Eco'\n",
        "train_data.loc[indices_Unknown[one_third_size:2*one_third_size], 'Class'] = 'Business'\n",
        "train_data.loc[indices_Unknown[2*one_third_size:], 'Class'] = 'Eco Plus'\n",
        "\n",
        "# If there are additional 'Unknown' entries due to non-divisibility, distribute them evenly\n",
        "if additional:\n",
        "    if additional == 1:\n",
        "        train_data.loc[indices_Unknown[2*one_third_size], 'Class'] = 'Eco'\n",
        "    elif additional == 2:\n",
        "        train_data.loc[indices_Unknown[2*one_third_size], 'Class'] = 'Eco'\n",
        "        train_data.loc[indices_Unknown[2*one_third_size + 1], 'Class'] = 'Business'\n",
        "\n",
        "\n",
        "data = train_data\n",
        "# Map 'satisfaction' to binary values\n",
        "data['satisfaction'] = data['satisfaction'].map({'satisfied': 1, 'neutral or dissatisfied': 0})\n",
        "\n",
        "bins = range(0, int(data['Age'].max()) + 10 , 10)\n",
        "data['Age'] = pd.cut(data['Age'], bins)\n",
        "\n",
        "data['Type of Travel'] = data['Type of Travel']\n",
        "\n",
        "indices_to_remove = data[data[\"Class\"] == \"IT IS SO BORING WORKING IN AN AIRPORT'S DESK OH MY GODDDDD\"].index\n",
        "data = data.drop(indices_to_remove) # Drop the rows by index\n",
        "\n",
        "#bins = range(0, int(data['Flight Distance'].max()) + 500 , 500) # dont need to split to bins, as recommended by the TA comments\n",
        "#data['Flight Distance'] = pd.cut(data['Flight Distance'], bins) #בגלל הערה שקבלנו בחלק הראשון\n",
        "\n",
        "\n",
        "data['Gate location'] = data['Gate location'].map({1.0: 1,2.0: 2, 3.0: 3,4.0: 4,5.0: 5,999.0:None, None:None}) # removing the outliers\n",
        "\n",
        "bins = range(0, int(train_data['Departure Delay in Minutes'].max()) + 50 , 50)\n",
        "data['Departure Delay in Minutes'] = pd.cut(data['Departure Delay in Minutes'], bins , include_lowest=True)\n",
        "\n",
        "bins = range(0, int(train_data['Arrival Delay in Minutes'].max()) + 50 , 50)\n",
        "data['Arrival Delay in Minutes'] = pd.cut(data['Arrival Delay in Minutes'], bins, include_lowest=True)\n",
        "\n",
        "# Remove rows where any of the specified columns have null values\n",
        "data = data.dropna(subset=['Gender', 'Customer Type', 'Age', 'Type of Travel', 'Class',\n",
        "       'Flight Distance', 'Plane colors', 'Inflight wifi service',\n",
        "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
        "       'Gate location', 'Food and drink', 'Seat comfort', 'On-board service',\n",
        "       'Baggage handling', 'Checkin service',\n",
        "       'Inflight service', 'Cleanliness', 'Departure Delay in Minutes',\n",
        "       'satisfaction'])\n",
        "\n",
        "y_train = data['satisfaction']\n",
        "X_train = data.drop(columns = ['satisfaction'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labeling"
      ],
      "metadata": {
        "id": "UmJOTD8xADFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Labeling Categorical Data\n",
        "age_bins = sorted(list(X_train['Age'].unique()))\n",
        "arrivals_bins = sorted(list(X_train['Arrival Delay in Minutes'].unique()))\n",
        "departure_bins = sorted(list(X_train['Departure Delay in Minutes'].unique()))\n",
        "labels_for_age = {interval: i+1 for i, interval in enumerate(age_bins)}\n",
        "labels_for_arrivals = {interval: i+1 for i, interval in enumerate(arrivals_bins)}\n",
        "labels_for_departure = {interval: i+1 for i, interval in enumerate(departure_bins)}"
      ],
      "metadata": {
        "id": "uUlueOmEfAKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train['Age'] = X_train['Age'].map(labels_for_age)\n",
        "#X_train['Arrival Delay in Minutes'] = X_train['Arrival Delay in Minutes'].map(labels_for_arrivals)\n",
        "#X_train['Departure Delay in Minutes'] = X_train['Departure Delay in Minutes'].map(labels_for_departure)"
      ],
      "metadata": {
        "id": "0mymQa-u4qeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Labeling Categorical Data\n",
        "#gender_map = {'Male': 0, 'Female': 1}\n",
        "#customer_type_map = {item: i for i, item in enumerate(list(X_train['Customer Type'].unique()))}  #{'Loyal Customer': 0, 'disloyal Customer': 1}\n",
        "#travel_type_map = {item: i for i, item in enumerate(list(X_train['Type of Travel'].unique()))} #{'Personal Travel': 0, 'Business travel': 1}\n",
        "#class_map = {Class: i+1 for i, Class in enumerate(list(X_train['Class'].unique()))} #{'Eco': 1, 'Eco Plus': 2, 'Business': 3}"
      ],
      "metadata": {
        "id": "SX1p8auB3n9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Maping each column (Labeling)\n",
        "#X_train['Gender'] = X_train['Gender'].map(gender_map)\n",
        "#X_train['Customer Type'] = X_train['Customer Type'].map(customer_type_map)\n",
        "#X_train['Type of Travel'] = X_train['Type of Travel'].map(travel_type_map)\n",
        "#X_train['Class'] = X_train['Class'].map(class_map)"
      ],
      "metadata": {
        "id": "C4zvf0YE8iLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT9_VAOvQKPL"
      },
      "source": [
        "#Fitting the NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY-luJQrQXkQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "#to fix normalization\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASrK0NPYOoLH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#x train_matrix and y victor\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_train, y_train, test_size=1/11, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-UQiWPWiyar"
      },
      "outputs": [],
      "source": [
        "#normalization\n",
        "standard_scaler = StandardScaler()\n",
        "X_train_s = standard_scaler.fit_transform(X_train)\n",
        "X_test_s = standard_scaler.transform(X_test)\n",
        "minmax_scaler = MinMaxScaler()\n",
        "X_train_n = minmax_scaler.fit_transform(X_train) # we decide to go with the StandardScaler Norrmilaztion!!!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_s.shape, X_test_s.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "P6zDYmJpH4dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXsPm6FPPlXw"
      },
      "outputs": [],
      "source": [
        "model = MLPClassifier(random_state=123,\n",
        "                      hidden_layer_sizes=(10),\n",
        "                      max_iter=1000,\n",
        "                      activation='relu',\n",
        "                      learning_rate_init=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AX8IUlcVQopY"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train_s, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R799bPA7a6EY"
      },
      "outputs": [],
      "source": [
        "predicted_values_train = model.predict(X_train_s)\n",
        "predicted_values_test = model.predict(X_test_s)\n",
        "\n",
        "train_score = accuracy_score(y_train,predicted_values_train)\n",
        "test_score = accuracy_score(y_test,predicted_values_test)\n",
        "f1score_train = f1_score(y_train, predicted_values_train)\n",
        "f1score_test = f1_score(y_test, predicted_values_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Score\")\n",
        "print(\"Train Accuracy: \" + str(train_score))\n",
        "print(\"Test Accuracy: \" + str(test_score))"
      ],
      "metadata": {
        "id": "Y0ePhY_pi0kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6qWTEEMbqqO"
      },
      "outputs": [],
      "source": [
        "print(\"F1 Score\")\n",
        "print(\"Train F1 Score: \" + str(f1score_train))\n",
        "print(\"Test F1 Score: \" + str(f1score_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE4kzwJETeH4"
      },
      "source": [
        "# סעיף 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvDKQRH2ituO"
      },
      "outputs": [],
      "source": [
        "neuron_numbers = [5,10,15,20,25,30,40,50,100]\n",
        "\n",
        "# Initialize lists to store train and test scores\n",
        "train_f1_scores = []\n",
        "test_f1_scores = []\n",
        "\n",
        "# Iterate over different numbers of neurons\n",
        "for neurons in neuron_numbers:\n",
        "    # Create MLPClassifier with current number of neurons\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(neurons,), max_iter=1000, random_state=123)\n",
        "\n",
        "    # Train the model\n",
        "    mlp.fit(X_train_s, y_train)\n",
        "\n",
        "    # Predict on train set\n",
        "    train_preds = mlp.predict(X_train_s)\n",
        "    train_f1 = f1_score(y_train, train_preds)\n",
        "    train_f1_scores.append(train_f1)\n",
        "\n",
        "    # Predict on test set\n",
        "    test_preds = mlp.predict(X_test_s)\n",
        "    test_f1 = f1_score(y_test, test_preds)\n",
        "    test_f1_scores.append(test_f1)\n",
        "\n",
        "# Plotting the graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(neuron_numbers, train_f1_scores, marker='o', label='Train Accuracy')\n",
        "plt.plot(neuron_numbers, test_f1_scores, marker='o', label='Test Accuracy')\n",
        "plt.title('MLPClassifier: Number of Neurons vs. Accuracy')\n",
        "plt.xlabel('Number of Neurons')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(neuron_numbers)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20 NEURONS IS THE BEST CHOICE if we use the accuarcy metric <br>\n",
        "25 neurons is the best choice by f1_score\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oDkzwC0TMDdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activations = ['logistic', 'tanh', 'relu', 'identity']\n",
        "train_f1_scores = []\n",
        "test_f1_scores = []\n",
        "\n",
        "# Loop over each activation function\n",
        "for activation in activations:\n",
        "    # Create MLPClassifier with specified parameters\n",
        "    model = MLPClassifier(random_state=123,\n",
        "                          hidden_layer_sizes=(20,),\n",
        "                          max_iter=40,\n",
        "                          activation=activation,\n",
        "                          verbose=False,\n",
        "                          learning_rate_init=0.01,\n",
        "                          early_stopping=True,\n",
        "                          solver='adam',\n",
        "                          alpha=10/460)\n",
        "\n",
        "    # Fit the model on training data\n",
        "    model.fit(X_train_s, y_train)\n",
        "\n",
        "    # Predict on training set\n",
        "    train_preds = model.predict(X_train_s)\n",
        "    train_f1 = f1_score(y_train, train_preds)\n",
        "    train_f1_scores.append(train_f1)\n",
        "\n",
        "    # Predict on test set\n",
        "    test_preds = model.predict(X_test_s)\n",
        "    test_f1 = f1_score(y_test, test_preds)\n",
        "    test_f1_scores.append(test_f1)\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(activations))\n",
        "\n",
        "bars_train = plt.bar(index, train_f1_scores, bar_width, label='Train F1 Score')\n",
        "bars_test = plt.bar(index + bar_width, test_f1_scores, bar_width, label='Test F1 Score')\n",
        "\n",
        "# Add labels and text annotations\n",
        "plt.xlabel('Activation Function')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Training and Test F1 Score for Different Activation Functions')\n",
        "plt.xticks(index + bar_width / 2, activations)\n",
        "plt.legend()\n",
        "\n",
        "# Function to annotate bars with F1 score values\n",
        "def annotate_bars(bars):\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.2f}', ha='center', va='bottom')\n",
        "\n",
        "# Annotate the bars\n",
        "annotate_bars(bars_train)\n",
        "annotate_bars(bars_test)\n",
        "\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H0tIknCgP5s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "best activiation function: **logistic** by accuarcy metrics <br>\n",
        "best activiation function: **relu** by f1 score metric"
      ],
      "metadata": {
        "id": "-bp4leLoyDOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "solvers = ['adam', 'sgd', 'lbfgs']\n",
        "train_f1_scores = []\n",
        "test_f1_scores = []\n",
        "\n",
        "# Loop over each solver\n",
        "for solver in solvers:\n",
        "    # Create MLPClassifier with specified parameters\n",
        "    model = MLPClassifier(random_state=123,\n",
        "                          hidden_layer_sizes=(20,),\n",
        "                          max_iter=40,\n",
        "                          activation='relu',  # Example activation function\n",
        "                          verbose=False,\n",
        "                          learning_rate_init=0.01,\n",
        "                          early_stopping=True,\n",
        "                          solver=solver,\n",
        "                          alpha=10/460)\n",
        "\n",
        "    # Fit the model on training data\n",
        "    model.fit(X_train_s, y_train)\n",
        "\n",
        "    # Predict on training set\n",
        "    train_preds = model.predict(X_train_s)\n",
        "    train_f1 = f1_score(y_train, train_preds)\n",
        "    train_f1_scores.append(train_f1)\n",
        "\n",
        "    # Predict on test set\n",
        "    test_preds = model.predict(X_test_s)\n",
        "    test_f1 = f1_score(y_test, test_preds)\n",
        "    test_f1_scores.append(test_f1)\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(solvers))\n",
        "\n",
        "bars_train = plt.bar(index, train_f1_scores, bar_width, label='Train')\n",
        "bars_test = plt.bar(index + bar_width, test_f1_scores, bar_width, label='Test')\n",
        "\n",
        "# Add labels and text annotations\n",
        "plt.xlabel('Solver')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Training and Test F1 Score for Different Solvers')\n",
        "plt.xticks(index + bar_width / 2, solvers)\n",
        "plt.legend()\n",
        "\n",
        "# Function to annotate bars with F1 score values\n",
        "def annotate_bars(bars):\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.2f}', ha='center', va='bottom')\n",
        "\n",
        "# Annotate the bars\n",
        "annotate_bars(bars_train)\n",
        "annotate_bars(bars_test)\n",
        "\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V5fmODw7Ziet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "best solver : **lbfgs** <br>\n",
        "best solver : **lbfgs** also by f1 score"
      ],
      "metadata": {
        "id": "mBIcDmAvxu1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.001, 0.01, 0.1, 1.0]\n",
        "train_accs = []\n",
        "test_accs = []\n",
        "\n",
        "# Loop over each learning rate\n",
        "for lr in learning_rates:\n",
        "    # Create MLPClassifier with specified parameters\n",
        "    model = MLPClassifier(random_state=123,\n",
        "                          hidden_layer_sizes=(20,),\n",
        "                          max_iter=40,\n",
        "                          activation='relu',\n",
        "                          verbose=False,\n",
        "                          learning_rate_init=lr,\n",
        "                          early_stopping=True,\n",
        "                          solver='adam',\n",
        "                          alpha=10/460)\n",
        "\n",
        "    # Fit the model on training data\n",
        "    model.fit(X_train_s, y_train)\n",
        "\n",
        "    # Calculate training accuracy\n",
        "    train_acc = accuracy_score(y_train, model.predict(X_train_s))\n",
        "    train_accs.append(train_acc)\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    test_acc = accuracy_score(y_test, model.predict(X_test_s))\n",
        "    test_accs.append(test_acc)\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(learning_rates))\n",
        "\n",
        "bars_train = plt.bar(index, train_accs, bar_width, label='Train')\n",
        "bars_test = plt.bar(index + bar_width, test_accs, bar_width, label='Test')\n",
        "\n",
        "# Add labels and text annotations\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Test Accuracy for Different Learning Rates')\n",
        "plt.xticks(index + bar_width / 2, learning_rates)\n",
        "plt.legend()\n",
        "\n",
        "# Function to annotate bars with accuracy values\n",
        "def annotate_bars(bars):\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 2), ha='center', va='bottom')\n",
        "\n",
        "# Annotate the bars\n",
        "annotate_bars(bars_train)\n",
        "annotate_bars(bars_test)\n",
        "\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dNLLgsg4w-6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the best learning rate: 0.1"
      ],
      "metadata": {
        "id": "ZOgQxJ6IyYJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.001, 0.01, 0.1, 1.0]\n",
        "train_f1_scores = []\n",
        "test_f1_scores = []\n",
        "\n",
        "# Loop over each learning rate\n",
        "for lr in learning_rates:\n",
        "    # Create MLPClassifier with specified parameters\n",
        "    model = MLPClassifier(random_state=123,\n",
        "                          hidden_layer_sizes=(20,),\n",
        "                          max_iter=40,\n",
        "                          activation='relu',\n",
        "                          verbose=False,\n",
        "                          learning_rate_init=lr,\n",
        "                          early_stopping=True,\n",
        "                          solver='adam',\n",
        "                          alpha=10/460)\n",
        "\n",
        "    # Fit the model on training data\n",
        "    model.fit(X_train_s, y_train)\n",
        "\n",
        "    # Predict on training set\n",
        "    train_preds = model.predict(X_train_s)\n",
        "    train_f1 = f1_score(y_train, train_preds)\n",
        "    train_f1_scores.append(train_f1)\n",
        "\n",
        "    # Predict on test set\n",
        "    test_preds = model.predict(X_test_s)\n",
        "    test_f1 = f1_score(y_test, test_preds)\n",
        "    test_f1_scores.append(test_f1)\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(learning_rates))\n",
        "\n",
        "bars_train = plt.bar(index, train_f1_scores, bar_width, label='Train')\n",
        "bars_test = plt.bar(index + bar_width, test_f1_scores, bar_width, label='Test')\n",
        "\n",
        "# Add labels and text annotations\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Training and Test F1 Score for Different Learning Rates')\n",
        "plt.xticks(index + bar_width / 2, learning_rates)\n",
        "plt.legend()\n",
        "\n",
        "# Function to annotate bars with F1 score values\n",
        "def annotate_bars(bars):\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.2f}', ha='center', va='bottom')\n",
        "\n",
        "# Annotate the bars\n",
        "annotate_bars(bars_train)\n",
        "annotate_bars(bars_test)\n",
        "\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_PP6r0d_K9eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the best learning rate: **0.01** by f1 score"
      ],
      "metadata": {
        "id": "cgSkFhEELMlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# סעיף 4"
      ],
      "metadata": {
        "id": "VUwziSHExSTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "הרצת הרשת הניורנים באמצעות הקונפיגוריצה הנבחרת מהסעיף הקודם <br>  activation='logistic'<br>  \n",
        "solver='lbfgs''<br>  \n",
        "learning_rate_init=0.1<br>  \n",
        "hidden_layer_sizes=(20,)\n"
      ],
      "metadata": {
        "id": "0Iw2LEJGyy1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_model = MLPClassifier(random_state=123,\n",
        "                          hidden_layer_sizes=(20,),\n",
        "                          max_iter=40,\n",
        "                          activation='logistic',\n",
        "                          verbose=False,\n",
        "                          learning_rate_init=0.1,\n",
        "                          early_stopping=True,\n",
        "                          solver='lbfgs',\n",
        "                          alpha=10/460)"
      ],
      "metadata": {
        "id": "HrzqqFM-xRiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_model.fit(X_train_s, y_train)"
      ],
      "metadata": {
        "id": "jaw9XZOtyoUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_predicted_values_train = optimal_model.predict(X_train_s)\n",
        "optimal_predicted_values_test = optimal_model.predict(X_test_s)\n",
        "\n",
        "train_score_op = accuracy_score(y_train,optimal_predicted_values_train)\n",
        "test_score_op = accuracy_score(y_test,optimal_predicted_values_test)\n",
        "f1score_train_op = f1_score(y_train, optimal_predicted_values_train)\n",
        "f1score_test_op = f1_score(y_test,optimal_predicted_values_test)"
      ],
      "metadata": {
        "id": "atn1__D50BYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Score With the Best Configuration\")\n",
        "print(\"Train Accuracy: \" + str(train_score_op))\n",
        "print(\"Test Accuracy: \" + str(test_score_op))"
      ],
      "metadata": {
        "id": "oqI6JBnG0bN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"F1 Score With the Best Configuration\")\n",
        "print(\"Train F1 Score: \" + str(f1score_train_op))\n",
        "print(\"Test F1 Score: \" + str(f1score_test_op))"
      ],
      "metadata": {
        "id": "1apfrmWa0rFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#סעיף 4 לפי f1\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrueHMTWLs33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "הרצת הרשת הניורנים באמצעות הקונפיגוריצה הנבחרת מהסעיף הקודם <br>  activation='relu'<br>  \n",
        "solver='lbfgs''<br>  \n",
        "learning_rate_init=0.01<br>  \n",
        "hidden_layer_sizes=(25,)\n"
      ],
      "metadata": {
        "id": "ibrxsOe3MCzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_model_f1 = MLPClassifier(random_state=123,\n",
        "                          hidden_layer_sizes=(25,),\n",
        "                          max_iter=40,\n",
        "                          activation='relu',\n",
        "                          verbose=False,\n",
        "                          learning_rate_init=0.01,\n",
        "                          early_stopping=True,\n",
        "                          solver='lbfgs',\n",
        "                          alpha=10/460)"
      ],
      "metadata": {
        "id": "Cm9ppgayLqr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_model_f1.fit(X_train_s, y_train)"
      ],
      "metadata": {
        "id": "n_IPrNTKMLR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_predicted_f1_values_train = optimal_model_f1.predict(X_train_s)\n",
        "optimal_predicted_f1_values_test = optimal_model_f1.predict(X_test_s)\n",
        "\n",
        "train_score_op_f1 = accuracy_score(y_train,optimal_predicted_f1_values_train)\n",
        "test_score_op_f1 = accuracy_score(y_test,optimal_predicted_f1_values_test)\n",
        "f1score_train_op_f1 = f1_score(y_train, optimal_predicted_f1_values_train)\n",
        "f1score_test_op_f1 = f1_score(y_test,optimal_predicted_f1_values_test)"
      ],
      "metadata": {
        "id": "bSMCUk4qMSLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Score With the Best Configuration\")\n",
        "print(\"Train Accuracy: \" + str(train_score_op_f1))\n",
        "print(\"Test Accuracy: \" + str(test_score_op_f1))"
      ],
      "metadata": {
        "id": "pdYRauE3MkIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"F1 Score With the Best Configuration\")\n",
        "print(\"Train F1 Score: \" + str(f1score_train_op_f1))\n",
        "print(\"Test F1 Score: \" + str(f1score_test_op_f1))"
      ],
      "metadata": {
        "id": "UNZoR0fmMnK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**END**"
      ],
      "metadata": {
        "id": "rCBOKi6TM8Od"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}